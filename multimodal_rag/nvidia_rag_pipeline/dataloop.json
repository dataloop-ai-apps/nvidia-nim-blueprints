{
  "name": "nim-rag-bp",
  "version": "0.0.51",
  "attributes": {
    "Category": [
      "Pipeline",
      "Blueprint"
    ],
    "Hub": [
      "Nvidia",
      "Dataloop"
    ],
    "Pipeline Type": "GenAI",
    "Provider": "NVIDIA",
    "Developed By": "Dataloop",
    "Media Type": [
      "Text"
    ]
  },
  "displayName": "RAG Pipeline NVIDIA Blueprint",
  "description": "RAG retrieval pipeline powered by NVIDIA NIM. Retrieves prepared embeddings from multimodal PDFs, uses NIM models for generating query embeddings and responses, and incorporates a retriever service to fetch relevant documents. Responses are stored in a prompts dataset and sent to a labeling task for human-in-the-loop validation. This is the second stage — first run the 'RAG Preprocessing Multimodal PDFs' pipeline to embed your documents. Setup: (1) Install this app — requires an NVIDIA NGC API key, which can be set up in advance as a secret integration or created during installation when prompted. (2) Create a pipeline from the 'RAG Pipeline NVIDIA Blueprint' template. (3) Model variables are preset to Llama 3.2 Nemoretriever 300M Embed V2 (query embedding and retrieval) and Llama 3.1 8B Instruct (response generation). To use different models, copy a model ID from Model Management into the pipeline's Variables panel. (4) Set 'retrieval_dataset' to the dataset containing your preprocessed embeddings. (5) Adjust 'k_nearest_items' if needed (default: 30). (6) Execute the pipeline.",
  "scope": "public",
  "components": {
    "pipelineTemplates": [
      {
        "connections": [
          {
            "src": {
              "nodeId": "64e7bc35-6b01-4970-ae0c-6100ab16684c",
              "portId": "e0743430-661b-4525-9b67-4e29b3e57be3"
            },
            "tgt": {
              "nodeId": "658203ec-ae8b-4064-af80-54e422e925d0",
              "portId": "5bc42361-46e6-4211-a2ea-442b9bbef08c"
            },
            "condition": "{}"
          },
          {
            "src": {
              "nodeId": "64e7bc35-6b01-4970-ae0c-6100ab16684c",
              "portId": "77e9397d-f9ec-4ff2-a57e-60427f40600b"
            },
            "tgt": {
              "nodeId": "658203ec-ae8b-4064-af80-54e422e925d0",
              "portId": "77deddf0-4bbd-40b2-8f09-f3572248901d"
            },
            "condition": "{}"
          },
          {
            "src": {
              "nodeId": "658203ec-ae8b-4064-af80-54e422e925d0",
              "portId": "808ce4ff-e358-47b2-98f2-37c037f28e5f"
            },
            "tgt": {
              "nodeId": "617bd7e9-5ab0-45be-91dc-e3ded9024db9",
              "portId": "2f4e3379-35c3-4fac-863a-ad8bd397a93d"
            },
            "condition": "{}"
          }
        ],
        "startNodes": [
          {
            "nodeId": "64e7bc35-6b01-4970-ae0c-6100ab16684c",
            "type": "root",
            "id": "1b5b0181-c7bc-449c-bf4e-c6803c928946"
          }
        ],
        "description": "NVIDIA blueprint RAG retrieval pipeline.",
        "name": "RAG Pipeline NVIDIA Blueprint",
        "nodes": [
          {
            "id": "64e7bc35-6b01-4970-ae0c-6100ab16684c",
            "inputs": [
              {
                "portId": "90c88062-8eaf-46fe-a4c0-13cac394ee71",
                "nodeId": "90c88062-8eaf-46fe-a4c0-13cac394ee71",
                "type": "Item",
                "name": "item",
                "displayName": "item",
                "io": "input"
              }
            ],
            "outputs": [
              {
                "portId": "e0743430-661b-4525-9b67-4e29b3e57be3",
                "nodeId": "e0743430-661b-4525-9b67-4e29b3e57be3",
                "type": "Item",
                "name": "item",
                "displayName": "item",
                "io": "output"
              },
              {
                "portId": "77e9397d-f9ec-4ff2-a57e-60427f40600b",
                "nodeId": "77e9397d-f9ec-4ff2-a57e-60427f40600b",
                "type": "Json",
                "name": "json",
                "displayName": "json",
                "io": "output"
              }
            ],
            "name": "Embedding Model (Llama 3.2 Nemoretriever 300M Embed V2)",
            "type": "ml",
            "namespace": {
              "functionName": "embed",
              "serviceName": "",
              "moduleName": "",
              "packageName": "nim-llama-3-2-nemoretriever-300m-embed-v2"
            },
            "appName": "Llama 3.2 Nemoretriever 300M Embed V2",
            "dpkName": "nim-llama-3-2-nemoretriever-300m-embed-v2",
            "metadata": {
              "position": {
                "x": 10083,
                "y": 10092,
                "z": 0
              },
              "componentGroupName": "models",
              "repeatable": true,
              "variableModel": "embed_model",
              "pipelineNodeName": "llama-3-2-nemoretriever-300m-embed-v2",
              "mlType": "embeddings"
            }
          },
          {
            "id": "658203ec-ae8b-4064-af80-54e422e925d0",
            "inputs": [
              {
                "portId": "5bc42361-46e6-4211-a2ea-442b9bbef08c",
                "nodeId": "5bc42361-46e6-4211-a2ea-442b9bbef08c",
                "type": "Item",
                "name": "item",
                "displayName": "item",
                "io": "input"
              },
              {
                "portId": "a513355f-593b-410a-bc49-03b0a29e6f20",
                "nodeId": "a513355f-593b-410a-bc49-03b0a29e6f20",
                "type": "Model",
                "name": "embedder",
                "displayName": "embedder",
                "variableName": "embed_model",
                "io": "input"
              },
              {
                "portId": "a0c252ae-7ac3-4312-b860-6f91defc8479",
                "nodeId": "a0c252ae-7ac3-4312-b860-6f91defc8479",
                "type": "Dataset",
                "name": "dataset",
                "displayName": "dataset",
                "variableName": "retrieval_dataset",
                "io": "input"
              },
              {
                "portId": "77deddf0-4bbd-40b2-8f09-f3572248901d",
                "nodeId": "77deddf0-4bbd-40b2-8f09-f3572248901d",
                "type": "Json",
                "name": "embeddings",
                "displayName": "embeddings",
                "io": "input"
              },
              {
                "portId": "d032010e-c7d2-4876-a57a-bba2f90da3a5",
                "nodeId": "d032010e-c7d2-4876-a57a-bba2f90da3a5",
                "type": "Json",
                "name": "query",
                "displayName": "query",
                "io": "input"
              },
              {
                "portId": "6453b062-9da0-4166-a50c-37ed3acd7f4f",
                "nodeId": "6453b062-9da0-4166-a50c-37ed3acd7f4f",
                "type": "Integer",
                "name": "k",
                "displayName": "k",
                "variableName": "k_nearest_items",
                "io": "input"
              }
            ],
            "outputs": [
              {
                "portId": "808ce4ff-e358-47b2-98f2-37c037f28e5f",
                "nodeId": "808ce4ff-e358-47b2-98f2-37c037f28e5f",
                "type": "Item",
                "name": "item",
                "displayName": "item",
                "io": "output"
              }
            ],
            "name": "Retriever Prompt",
            "type": "custom",
            "namespace": {
              "functionName": "query_nearest_items_prompt",
              "serviceName": "retriever-service",
              "moduleName": "retriever-module",
              "packageName": "llm-tools-retriever"
            },
            "appName": "Retriever",
            "dpkName": "llm-tools-retriever",
            "metadata": {
              "position": {
                "x": 10524.4248046875,
                "y": 10065.9775390625,
                "z": 0
              },
              "componentGroupName": "query",
              "customNodeConfig": {
                "name": "Retriever Prompt",
                "validation": {
                  "valid": true,
                  "errors": [
                  ]
                }
              },
              "repeatable": true,
              "pipelineNodeName": "Retriever Prompt"
            }
          },
          {
            "id": "617bd7e9-5ab0-45be-91dc-e3ded9024db9",
            "inputs": [
              {
                "portId": "2f4e3379-35c3-4fac-863a-ad8bd397a93d",
                "nodeId": "2f4e3379-35c3-4fac-863a-ad8bd397a93d",
                "type": "Item",
                "name": "item",
                "displayName": "item",
                "io": "input"
              }
            ],
            "outputs": [
              {
                "portId": "dc17f8af-4715-4c4c-9b1d-19aac4aa5b62",
                "nodeId": "dc17f8af-4715-4c4c-9b1d-19aac4aa5b62",
                "type": "Item",
                "name": "item",
                "displayName": "item",
                "io": "output"
              },
              {
                "portId": "3ebaeee3-bdfe-453f-a046-1c42da52a9d6",
                "nodeId": "3ebaeee3-bdfe-453f-a046-1c42da52a9d6",
                "type": "Annotation[]",
                "name": "annotations",
                "displayName": "annotations",
                "io": "output"
              }
            ],
            "name": "Response LLM (Llama 3.1 8B Instruct)",
            "type": "ml",
            "namespace": {
              "functionName": "predict",
              "serviceName": "",
              "moduleName": "",
              "packageName": "nim-llama-3-1-8b-instruct"
            },
            "appName": "Llama 3.1 8B Instruct",
            "dpkName": "nim-llama-3-1-8b-instruct",
            "metadata": {
              "position": {
                "x": 10878.4971501579,
                "y": 10089.9101439659,
                "z": 0
              },
              "componentGroupName": "models",
              "repeatable": true,
              "variableModel": "gen_ai_model",
              "pipelineNodeName": "nim-llama-3-1-8b-instruct",
              "mlType": "genAi"
            }
          }
        ],
        "variables": [
          {
            "name": "embed_model",
            "type": "Model",
            "description": "Embedding model used for embedding user prompt questions and for retrieval (must match the model used during preprocessing). Preset: Llama 3.2 Nemoretriever 300M Embed V2 (nim-llama-3-2-nemoretriever-300m-embed-v2)",
            "value": "$var(embed_model__model)"
          },
          {
            "name": "gen_ai_model",
            "type": "Model",
            "description": "Generative LLM for producing the final response from retrieved context. Preset: Llama 3.1 8B Instruct (nim-llama-3-1-8b-instruct)",
            "value": "$var(gen_ai_model__model)"
          },
          {
            "name": "retrieval_dataset",
            "type": "Dataset",
            "description": "Dataset containing embedded chunks from the RAG Preprocessing pipeline. Required — select the output dataset from the preprocessing stage.",
            "value": "$var(retrieval_dataset__dataset)"
          },
          {
            "name": "k_nearest_items",
            "type": "Integer",
            "description": "K nearest items - The number of closest items to retrieve. Default set to 30.",
            "value": 30
          }
        ]
      }
    ]
  },
  "dependencies": [
    {
      "name": "nim-llama-3-2-nemoretriever-300m-embed-v2"
    },
    {
      "name": "nim-llama-3-1-8b-instruct"
    },
    {
      "name": "llm-tools-retriever"
    }
  ],
  "variables": {
    "embed_model__model": "nim-llama-3-2-nemoretriever-300m-embed-v2.models.nim-llama-3-2-nemoretriever-300m-embed-v2",
    "gen_ai_model__model": "nim-llama-3-1-8b-instruct.models.nim-llama-3-1-8b-instruct"
  }
}
